<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Audio → MIDI (Matrix Edition)</title>
  <style>
    /* MATRIX THEME + Modern UI */
    :root{
      --bg:#020202;
      --panel:#07120b;
      --accent:#00ff7f;
      --muted:#3a3f3a;
      --glass: rgba(255,255,255,0.03);
      --radius: 12px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, "Roboto Mono", "Segoe UI Mono", "Helvetica Neue", monospace;
    }
    html,body{height:100%; margin:0; background:
      radial-gradient(ellipse at center, rgba(0,32,0,0.08), transparent 20%),
      linear-gradient(180deg, #021 0%, #000 100%); color:#bfffbf; font-family: Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial; -webkit-font-smoothing:antialiased;}
    main{max-width:1100px; margin:28px auto; padding:20px; }
    header{display:flex;align-items:center; gap:16px; margin-bottom:18px;}
    h1{margin:0; font-size:20px; letter-spacing:0.6px}
    .subtitle{color:var(--muted); font-size:13px;}
    .grid{display:grid; grid-template-columns: 420px 1fr; gap:18px;}
    .panel{background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)); border:1px solid rgba(0,255,127,0.06); padding:16px; border-radius:var(--radius); box-shadow: 0 6px 20px rgba(0,0,0,0.6), inset 0 1px 0 rgba(255,255,255,0.02);}
    label{display:block; font-weight:600; color:#bfffbf; margin-bottom:8px; font-size:13px}
    select,input[type=number], input[type=text], input[type=file]{background:transparent; border:1px solid rgba(255,255,255,0.06); color:#bfffbf; padding:8px 10px; border-radius:8px; outline:none; width:100%}
    .row{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
    button{background:linear-gradient(90deg,#063d27,#0b7a4a); color:#001; border:none; padding:10px 14px; border-radius:10px; cursor:pointer; font-weight:700; box-shadow: 0 4px 12px rgba(0,0,0,0.6); transition:transform .08s ease, box-shadow .08s;}
    button.secondary{background:transparent; color:var(--accent); border:1px solid rgba(0,255,127,0.12)}
    button:active{transform:translateY(1px)}
    small.note{display:block; color:#8fbf8f; margin-top:6px}
    .status{font-family:var(--mono); color:var(--accent); font-size:13px}
    .log{background:transparent; color:#bfffbf; margin-top:10px; font-size:13px}
    .controls{display:flex; gap:10px; align-items:center; flex-wrap:wrap; margin-top:12px}
    .progress{height:10px; background:rgba(0,0,0,0.3); border-radius:10px; overflow:hidden; border:1px solid rgba(255,255,255,0.02)}
    .progress > div{height:100%; width:0%; background:linear-gradient(90deg, rgba(0,255,127,0.2), rgba(0,255,127,0.6)); transition:width .3s ease}
    .stems a{display:block; margin:6px 0; color:var(--accent); text-decoration:none; font-weight:600}
    footer{margin-top:18px; color:var(--muted); font-size:13px}
    /* subtle matrix vertical lines background */
    body::after{content:''; position:fixed; inset:0; background-image:
      linear-gradient(rgba(0,255,127,0.02) 1px, transparent 1px);
      background-size: 1px 24px; pointer-events:none; opacity:0.06}
    @media(max-width:900px){
      .grid{grid-template-columns:1fr; }
      header{flex-direction:column; align-items:flex-start; gap:6px}
    }
  </style>
</head>
<body>
  <main>
    <header>
      <div>
        <h1>Audio → MIDI <span style="color:var(--accent)">Matrix</span></h1>
        <div class="subtitle">Hum / Record / Upload — server separation optional. Exports .mid for GarageBand.</div>
      </div>
      <div style="margin-left:auto" class="status" id="topStatus">Ready</div>
    </header>

    <div class="grid">
      <!-- Left column: controls -->
      <div class="panel">
        <label>Mode</label>
        <div class="row">
          <select id="modeSelect">
            <option value="hum">Hum / Whistle</option>
            <option value="song">Song (record / upload)</option>
          </select>
          <div style="width:10px"></div>
          <label style="min-width:120px">Tempo (BPM)</label>
          <input id="bpm" type="number" value="120" min="20" max="300" style="width:110px"/>
        </div>

        <label style="margin-top:12px">Quantize (ms)</label>
        <input id="quantizeMs" type="number" value="120" min="10" max="2000" />

        <div id="humPanel" style="margin-top:14px">
          <label>Hum / Whistle Mode</label>
          <div class="row controls">
            <button id="humStart">Start Listening</button>
            <button id="humStop" class="secondary" disabled>Stop & Generate</button>
            <button id="humPlay" class="secondary" disabled>Preview</button>
            <a id="humDownload" style="display:none"></a>
          </div>
          <div class="log" id="humLog"></div>
        </div>

        <div id="songPanel" style="display:none; margin-top:14px">
          <label>Song Mode</label>
          <div class="row">
            <select id="songSource">
              <option value="display">System audio (desktop only)</option>
              <option value="mic">Microphone</option>
              <option value="upload">Upload file (mp3/wav)</option>
            </select>
            <select id="songOutputMode">
              <option value="single">Single MIDI</option>
              <option value="separate">Separate / per stem</option>
            </select>
          </div>

          <div style="margin-top:10px" class="row">
            <label style="min-width:120px">Server Separation?</label>
            <select id="useServerSeparation">
              <option value="no">No — client only</option>
              <option value="yes">Yes — upload to Spleeter server</option>
            </select>
          </div>

          <div id="uploadRow" style="display:none; margin-top:10px">
            <input id="uploadFile" type="file" accept="audio/*" />
          </div>

          <div class="row controls" style="margin-top:10px">
            <button id="songStart">Start / Upload</button>
            <button id="songStop" class="secondary" disabled>Stop</button>
          </div>

          <div style="margin-top:10px">
            <label>Separation Server URL (if used)</label>
            <input id="serverUrl" type="text" value="http://localhost:3000" />
            <div style="margin-top:8px" class="row">
              <label style="min-width:120px">Spleeter mode</label>
              <select id="spleeterMode"><option value="2stems">2stems</option><option value="4stems">4stems</option><option value="5stems">5stems</option></select>
            </div>
          </div>
        </div>

      </div>

      <!-- Right column: info, stems, progress -->
      <div class="panel">
        <div class="row" style="justify-content:space-between; align-items:center">
          <div>
            <div style="font-weight:700; font-size:15px">Processing</div>
            <small class="small note">Use the server for best stem quality. Client fallback will still work for simple recordings.</small>
          </div>
          <div id="statusBox" class="status">Idle</div>
        </div>

        <div style="margin-top:12px">
          <div class="progress" aria-hidden><div id="progressBar"></div></div>
        </div>

        <div style="margin-top:12px" id="stemsArea">
          <div style="font-weight:700">Stems & Downloads</div>
          <div id="stemsContainer" class="stems"></div>
        </div>

        <div style="margin-top:14px" id="logArea">
          <div style="font-weight:700">Log</div>
          <div id="mainLog" class="log">No activity yet.</div>
        </div>

        <footer>
          <div>Tip: For best results upload an MP3/WAV or use system capture on desktop. Mobile browsers sometimes block tab/system capture — use upload for highest fidelity.</div>
        </footer>
      </div>
    </div>
  </main>

  <script>
  // ---------------- Utility: small MIDI builder (no external libs) ----------------
  // Builds a simple single-track MIDI file (Format 0). Returns a Blob.
  function writeVarLen(value) {
    // write value as MIDI variable length bytes (MSB continuation)
    const bytes = [];
    let buffer = value & 0x7F;
    value >>= 7;
    while (value > 0) {
      buffer <<= 8;
      buffer |= ((value & 0x7F) | 0x80);
      value >>= 7;
    }
    // now split buffer into bytes
    for (;;) {
      bytes.push(buffer & 0xFF);
      if (buffer & 0x80) buffer >>= 8;
      else break;
    }
    return bytes;
  }

  function intToBytesBE(val, bytes) {
    const out = [];
    for (let i = bytes-1; i>=0; i--) {
      out.push((val >> (8*i)) & 0xFF);
    }
    return out;
  }

  function buildMidiFromNotesSimple(noteSequence, bpm=120) {
    // noteSequence: [{midi, startTime, endTime}] with seconds
    // Convert to a single-track MIDI (format 0), ticksPerQuarter = 480
    const ticksPerQuarter = 480;
    const header = [];
    header.push(...[0x4d,0x54,0x68,0x64]); // MThd
    header.push(...intToBytesBE(6,4)); // header length
    header.push(...intToBytesBE(0,2)); // format 0
    header.push(...intToBytesBE(1,2)); // one track
    header.push(...intToBytesBE(ticksPerQuarter,2));

    // Build track events
    // We'll create NoteOn and NoteOff events using delta times in ticks.
    // Steps:
    // 1) sort noteSequence by startTime
    if (!noteSequence || noteSequence.length===0) {
      // empty MIDI - return a small empty track
      const emptyTrack = [];
      emptyTrack.push(...[0x00,0xFF,0x2F,0x00]); // end of track
      const trk = [0x4d,0x54,0x72,0x6b]; // MTrk
      trk.push(...intToBytesBE(emptyTrack.length,4));
      trk.push(...emptyTrack);
      const arr = new Uint8Array([...header, ...trk]);
      return new Blob([arr], {type:'audio/midi'});
    }

    noteSequence = noteSequence.slice().sort((a,b)=>a.startTime - b.startTime);

    // convert to a list of events: {time(ticks), type:'on'/'off', note, vel}
    const events = [];
    const mpq = Math.round(60000000 / bpm);
    // tempo meta event will be placed at start
    for (let n of noteSequence) {
      const startTicks = Math.round(n.startTime / (60 / bpm) * ticksPerQuarter);
      const durSec = Math.max(0.02, n.endTime - n.startTime);
      const durTicks = Math.max(1, Math.round(durSec / (60 / bpm) * ticksPerQuarter));
      events.push({time:startTicks, type:'on', note:n.midi, vel:100});
      events.push({time:startTicks + durTicks, type:'off', note:n.midi, vel:0});
    }
    // sort events by time, on before off if same time (so chord on/off are proper)
    events.sort((a,b)=> (a.time - b.time) || ((a.type==='on' && b.type==='off') ? -1 : 1));

    // Build track bytes
    const trackBytes = [];
    // delta-time 0, tempo meta event
    trackBytes.push(...[0x00, 0xFF, 0x51, 0x03, ...intToBytesBE(mpq,3)]);
    // optional program change (channel 0) to acoustic piano
    trackBytes.push(...[0x00, 0xC0, 0x00]);

    let lastTick = 0;
    for (let ev of events) {
      const delta = ev.time - lastTick;
      lastTick = ev.time;
      const varlen = writeVarLen(delta);
      trackBytes.push(...varlen);
      if (ev.type === 'on') {
        // Note On on channel 0: 0x90, note, vel
        trackBytes.push(0x90, ev.note & 0x7F, ev.vel & 0x7F);
      } else {
        // Note Off: 0x80, note, vel
        trackBytes.push(0x80, ev.note & 0x7F, ev.vel & 0x7F);
      }
    }
    // End of track
    trackBytes.push(...[0x00, 0xFF, 0x2F, 0x00]);

    const trkChunk = [0x4d,0x54,0x72,0x6b, ...intToBytesBE(trackBytes.length,4), ...trackBytes];
    const full = new Uint8Array([...header, ...trkChunk]);
    return new Blob([full], {type:'audio/midi'});
  }

  // ---------------- Pitch detection (autocorrelation) & helpers ----------------
  function autoCorrelateFloat(buffer, sampleRate) {
    const SIZE = buffer.length;
    let rms = 0;
    for (let i=0;i<SIZE;i++) rms += buffer[i]*buffer[i];
    rms = Math.sqrt(rms / SIZE);
    if (rms < 0.005) return -1;
    let r1=0, r2=SIZE-1, thresh=0.2;
    for (let i=0;i<SIZE/2;i++) if (Math.abs(buffer[i]) < thresh) { r1 = i; break; }
    for (let i=1;i<SIZE/2;i++) if (Math.abs(buffer[SIZE - i]) < thresh) { r2 = SIZE - i; break; }
    buffer = buffer.slice(r1, r2);
    const newSize = buffer.length;
    const c = new Array(newSize).fill(0);
    for (let i=0;i<newSize;i++) {
      for (let j=0;j<newSize - i;j++) c[i] += buffer[j] * buffer[j + i];
    }
    let d = 0;
    while (d < newSize -1 && c[d] > c[d+1]) d++;
    let maxpos = -1, maxval = -1;
    for (let i=d;i<newSize;i++) {
      if (c[i] > maxval) { maxval = c[i]; maxpos = i; }
    }
    if (maxpos <= 0) return -1;
    const T0 = maxpos;
    const freq = sampleRate / T0;
    if (!isFinite(freq) || freq <= 0 || freq > 10000) return -1;
    return freq;
  }
  function freqToMidi(f) { return Math.round(69 + 12 * Math.log2(f / 440)); }
  function midiToName(m) {
    const names = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'];
    const name = names[(m%12+12)%12];
    const oct = Math.floor(m/12) - 1;
    return name + oct;
  }

  // ---------------- App Logic (Hum + Song simplified) ----------------
  (function(){
    const modeSelect = document.getElementById('modeSelect');
    const humPanel = document.getElementById('humPanel');
    const songPanel = document.getElementById('songPanel');
    const topStatus = document.getElementById('topStatus');
    const statusBox = document.getElementById('statusBox');
    const progressBar = document.getElementById('progressBar');
    const mainLog = document.getElementById('mainLog');

    modeSelect.addEventListener('change', ()=> {
      if (modeSelect.value === 'hum') { humPanel.style.display='block'; songPanel.style.display='none'; }
      else { humPanel.style.display='none'; songPanel.style.display='block'; }
    });

    // element refs
    const humStartBtn = document.getElementById('humStart');
    const humStopBtn  = document.getElementById('humStop');
    const humPlayBtn  = document.getElementById('humPlay');
    const humDownload = document.getElementById('humDownload');
    const humLog = document.getElementById('humLog');

    let audioCtx = null, analyser = null, mediaStream = null, rafId = null;
    let bufferLength = 2048, dataArray = null;
    let detectedNotes = [], startBase = 0;

    async function humStart() {
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        setStatus('Mic permission denied or unavailable.');
        return;
      }
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = bufferLength;
      const src = audioCtx.createMediaStreamSource(mediaStream);
      src.connect(analyser);
      dataArray = new Float32Array(analyser.fftSize);
      detectedNotes = [];
      startBase = audioCtx.currentTime;
      humStartBtn.disabled = true; humStopBtn.disabled = false; humPlayBtn.disabled = true; humDownload.style.display='none';
      setStatus('Listening...');
      loopDetect();
    }

    function humStop() {
      if (mediaStream) mediaStream.getTracks().forEach(t=>t.stop());
      if (audioCtx) audioCtx.close();
      cancelAnimationFrame(rafId);
      humStartBtn.disabled=false; humStopBtn.disabled=true;
      setStatus('Stopped — building MIDI...');
      // quantize
      const qMs = parseInt(document.getElementById('quantizeMs').value||120,10);
      for (let n of detectedNotes) {
        n.startTime = Math.round(n.startTime * 1000 / qMs) * qMs / 1000;
        n.endTime   = Math.round(n.endTime   * 1000 / qMs) * qMs / 1000;
        if (n.endTime <= n.startTime) n.endTime = n.startTime + qMs/1000;
      }
      if (!detectedNotes.length) {
        setStatus('No notes detected. Try singing louder or closer.');
        humLog.innerText = '';
        return;
      }
      try {
        const blob = buildMidiFromNotesSimple(detectedNotes, parseInt(document.getElementById('bpm').value||120,10));
        const url = URL.createObjectURL(blob);
        humDownload.href = url; humDownload.download = 'hum_capture.mid';
        humDownload.style.display = 'inline-block'; humDownload.innerText = 'Download .mid';
        humPlayBtn.disabled = false;
        humLog.innerText = 'Detected: ' + detectedNotes.map(n=>midiToName(n.midi)).join(' ');
        setStatus('MIDI ready. Tap Download to save.');
      } catch (err) {
        setStatus('MIDI build error: ' + (err.message||err));
      }
    }

    function loopDetect() {
      const sr = audioCtx.sampleRate;
      analyser.getFloatTimeDomainData(dataArray);
      const freq = autoCorrelateFloat(dataArray, sr);
      const tNow = audioCtx.currentTime - startBase;
      if (freq > 0) {
        const midi = freqToMidi(freq);
        if (midi >= 21 && midi <= 108) {
          const last = detectedNotes.length ? detectedNotes[detectedNotes.length-1] : null;
          if (!last || Math.abs(last.midi - midi) > 1 || (tNow - last.endTime) > 0.12) {
            detectedNotes.push({midi:midi, startTime: tNow, endTime: tNow + 0.02});
          } else {
            last.endTime = tNow + 0.02;
          }
        }
      } else {
        // silence - no action; pending notes finalize through timeouts/quantize later
      }
      humLog.innerText = 'Listening... notes: ' + detectedNotes.length;
      rafId = requestAnimationFrame(loopDetect);
    }

    function humPreview() {
      previewSequence(detectedNotes, parseInt(document.getElementById('bpm').value||120,10));
    }

    humStartBtn.addEventListener('click', humStart);
    humStopBtn.addEventListener('click', humStop);
    humPlayBtn.addEventListener('click', humPreview);

    // ---------------- Preview function (simple oscillator)
    function previewSequence(noteSequence, bpm=120) {
      if (!noteSequence || !noteSequence.length) return;
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const base = noteSequence[0].startTime;
      let now = ctx.currentTime + 0.12;
      for (let n of noteSequence) {
        const osc = ctx.createOscillator();
        const g = ctx.createGain();
        const freq = 440 * Math.pow(2, (n.midi - 69)/12);
        osc.type = 'sine';
        osc.frequency.value = freq;
        g.gain.value = 0.08;
        osc.connect(g).connect(ctx.destination);
        const start = now + (n.startTime - base);
        const dur = Math.max(0.05, n.endTime - n.startTime);
        osc.start(start); osc.stop(start + dur);
      }
      setTimeout(()=>ctx.close(), Math.max(2000, (noteSequence[noteSequence.length-1].endTime - base) * 1000 + 1200));
    }

    // ---------------- Song mode: Upload or live (client-only simplified) ----------------
    const songStartBtn = document.getElementById('songStart');
    const songStopBtn = document.getElementById('songStop');
    const songSource = document.getElementById('songSource');
    const uploadRow = document.getElementById('uploadRow');
    const uploadFile = document.getElementById('uploadFile');
    const useServerSelect = document.getElementById('useServerSeparation');
    const serverUrlInput = document.getElementById('serverUrl');
    const spleeterModeSelect = document.getElementById('spleeterMode');
    const stemsContainer = document.getElementById('stemsContainer');

    songSource.addEventListener('change', ()=> {
      uploadRow.style.display = (songSource.value === 'upload') ? 'block' : 'none';
    });

    songStartBtn.addEventListener('click', async () => {
      // clear previous
      stemsContainer.innerHTML = ''; mainLog.innerText = '';
      const source = songSource.value;
      const useServer = useServerSelect.value === 'yes';
      setStatus('Starting song mode...');
      if (source === 'upload') {
        const file = uploadFile.files[0];
        if (!file) { setStatus('Choose a file first.'); return; }
        if (useServer) {
          // upload to server endpoint for separation
          try {
            setStatus('Uploading to separation server...');
            progressBar.style.width = '20%';
            const fd = new FormData();
            fd.append('file', file);
            fd.append('mode', spleeterModeSelect.value || '2stems');
            const res = await fetch((serverUrlInput.value || '').replace(/\/$/, '') + '/api/separate', { method: 'POST', body: fd });
            if (!res.ok) {
              const txt = await res.text();
              throw new Error('Server error: ' + txt);
            }
            const json = await res.json();
            progressBar.style.width = '100%';
            setStatus('Separation complete. Preparing stems...');
            showStems(json.stems);
          } catch (err) {
            setStatus('Separation failed: ' + err.message);
          }
        } else {
          // local client transcription of uploaded file
          try {
            setStatus('Decoding file (client)...');
            const ab = await file.arrayBuffer();
            const ctx = new (window.AudioContext || window.webkitAudioContext)();
            const buffer = await ctx.decodeAudioData(ab).catch(()=>null);
            if (!buffer) { setStatus('Could not decode file in this browser. Use upload on a desktop or use server.'); return; }
            setStatus('Detecting notes (client)...');
            const notes = await audioBufferToNotes(buffer);
            if (!notes.length) { setStatus('No notes detected.'); return; }
            const qMs = parseInt(document.getElementById('quantizeMs').value||120,10);
            for (let n of notes) {
              n.startTime = Math.round(n.startTime * 1000 / qMs) * qMs / 1000;
              n.endTime   = Math.round(n.endTime * 1000 / qMs) * qMs / 1000;
              if (n.endTime <= n.startTime) n.endTime = n.startTime + qMs/1000;
            }
            const blob = buildMidiFromNotesSimple(notes, parseInt(document.getElementById('bpm').value||120,10));
            const link = createDownloadLink(blob, 'uploaded_song.mid');
            stemsContainer.appendChild(link);
            setStatus('MIDI ready.');
          } catch (err) {
            setStatus('Processing error: ' + err.message);
          }
        }
      } else if (source === 'mic' || source === 'display') {
        // start a simple MediaRecorder capture until Stop pressed
        try {
          setStatus('Requesting permission for capture...');
          const stream = (source === 'display') ? await navigator.mediaDevices.getDisplayMedia({audio:true, video:false}) : await navigator.mediaDevices.getUserMedia({audio:true});
          const options = { mimeType: 'audio/webm' };
          const recorder = new MediaRecorder(stream, options);
          const chunks = [];
          recorder.ondataavailable = e=> { if (e.data && e.data.size) chunks.push(e.data); };
          recorder.onstop = async () => {
            setStatus('Recording stopped. Decoding...');
            const blob = new Blob(chunks, {type:'audio/webm'});
            const ab = await blob.arrayBuffer();
            const ctx = new (window.AudioContext || window.webkitAudioContext)();
            const buf = await ctx.decodeAudioData(ab).catch(()=>null);
            if (!buf) { setStatus('Could not decode recorded audio. Try upload.'); return; }
            if (useServer) {
              // send blob to server for separation
              try {
                setStatus('Uploading recorded audio to server for separation...');
                const fd = new FormData();
                fd.append('file', new File([blob], 'recording.webm', {type: 'audio/webm'}));
                fd.append('mode', spleeterModeSelect.value || '2stems');
                const res = await fetch((serverUrlInput.value || '').replace(/\/$/, '') + '/api/separate', { method: 'POST', body: fd });
                if (!res.ok) throw new Error('Server error');
                const json = await res.json();
                setStatus('Separation complete. Preparing stems...');
                showStems(json.stems);
              } catch (err) {
                setStatus('Server separation failed: ' + err.message);
              }
            } else {
              setStatus('Transcribing recorded audio (client)...');
              const notes = await audioBufferToNotes(buf);
              if (!notes.length) { setStatus('No notes detected.'); return; }
              const blobm = buildMidiFromNotesSimple(notes, parseInt(document.getElementById('bpm').value||120,10));
              stemsContainer.appendChild(createDownloadLink(blobm, 'recording.mid'));
              setStatus('MIDI ready.');
            }
          };
          recorder.start();
          setStatus('Recording... press Stop when finished.');
          songStopBtn.disabled = false;
          songStopBtn.onclick = () => { recorder.stop(); stream.getTracks().forEach(t=>t.stop()); songStopBtn.disabled=true; };
        } catch (err) {
          setStatus('Capture failed: ' + err.message);
        }
      }
    });

    function setStatus(txt){ topStatus.innerText = txt; statusBox.innerText = txt; mainLog.innerText = txt; }

    async function showStems(stems) {
      stemsContainer.innerHTML = '';
      if (!stems || !stems.length) { setStatus('No stems returned'); return; }
      for (let s of stems) {
        const block = document.createElement('div');
        block.style.marginBottom = '8px';
        const btn = document.createElement('button'); btn.innerText = 'Preview ' + s.name; btn.style.marginRight='8px';
        const trans = document.createElement('button'); trans.innerText = 'Transcribe → MIDI';
        const href = document.createElement('a'); href.href = s.url; href.innerText = s.name; href.target='_blank'; href.style.marginLeft='8px'; href.style.color='var(--accent)';
        block.appendChild(btn); block.appendChild(trans); block.appendChild(href);
        stemsContainer.appendChild(block);

        btn.addEventListener('click', async ()=> {
          try {
            setStatus('Downloading stem for preview...');
            const ab = await fetch(s.url).then(r=>r.arrayBuffer());
            const ctx = new (window.AudioContext || window.webkitAudioContext)();
            const buff = await ctx.decodeAudioData(ab);
            const src = ctx.createBufferSource(); src.buffer = buff; src.connect(ctx.destination); src.start();
            setTimeout(()=>{ try{ src.stop(); ctx.close(); setStatus('Preview finished.'); } catch(e){} }, Math.min(20000, buff.duration*1000));
          } catch (err) {
            setStatus('Preview failed: ' + err.message);
          }
        });

        trans.addEventListener('click', async ()=> {
          try {
            setStatus('Downloading stem for transcription...');
            const ab = await fetch(s.url).then(r=>r.arrayBuffer());
            const ctx = new (window.AudioContext || window.webkitAudioContext)();
            const buff = await ctx.decodeAudioData(ab);
            setStatus('Detecting notes...');
            const notes = await audioBufferToNotes(buff);
            if (!notes.length) { setStatus('No notes detected for ' + s.name); return; }
            // quantize
            const qMs = parseInt(document.getElementById('quantizeMs').value||120,10);
            for (let n of notes) {
              n.startTime = Math.round(n.startTime * 1000 / qMs) * qMs / 1000;
              n.endTime   = Math.round(n.endTime * 1000 / qMs) * qMs / 1000;
              if (n.endTime <= n.startTime) n.endTime = n.startTime + qMs/1000;
            }
            const blob = buildMidiFromNotesSimple(notes, parseInt(document.getElementById('bpm').value||120,10));
            const link = createDownloadLink(blob, (s.name.replace(/\.[^/.]+$/,'') || 'stem') + '.mid');
            stemsContainer.appendChild(link);
            setStatus('Transcription ready for ' + s.name);
          } catch (err) {
            setStatus('Transcription error: ' + err.message);
          }
        });
      }
    }

    function createDownloadLink(blob, filename) {
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url; a.download = filename; a.innerText = 'Download ' + filename; a.style.display='block'; a.style.color='var(--accent)';
      return a;
    }

    // audioBuffer -> notes (chunked autocorrelation)
    async function audioBufferToNotes(audioBuffer) {
      const sr = audioBuffer.sampleRate;
      const data = audioBuffer.getChannelData(0);
      const chunk = 2048;
      const notes = [];
      let pending = null;
      for (let i=0;i<data.length;i+=chunk) {
        const sub = data.subarray(i, Math.min(i+chunk, data.length));
        const f = autoCorrelateFloat(sub, sr);
        const tNow = i / sr;
        if (f > 0) {
          const m = freqToMidi(f);
          if (!pending) pending = {midi:m, startTime:tNow, endTime:tNow + chunk/sr};
          else {
            if (Math.abs(pending.midi - m) > 1) { notes.push(Object.assign({}, pending)); pending = {midi:m, startTime:tNow, endTime:tNow + chunk/sr}; }
            else pending.endTime = tNow + chunk/sr;
          }
        } else {
          if (pending && (tNow - pending.endTime) > 0.08) { notes.push(Object.assign({}, pending)); pending = null; }
        }
      }
      if (pending) notes.push(Object.assign({}, pending));
      return notes;
    }

    // expose for debugging in mobile dev console
    window._app = { buildMidiFromNotesSimple };

  })();

  </script>
</body>
</html>
